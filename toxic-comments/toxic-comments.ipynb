{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "composite-camping",
   "metadata": {},
   "source": [
    "# Токсичные комментарии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-dependence",
   "metadata": {},
   "source": [
    "Целью проекта является получение моделей для выявления токсичных описаний и комментариев к продуктам интернет-магазина. Для обучения моделей имеется массив описаний и комментариев с пометкой токсичны они или нет.\n",
    "\n",
    "Для достижения цели, будут выполнены следующие шаги:\n",
    "\n",
    "**<a href=\"#prepare\">1. Подготовка.</a>** Данные будут загружены, проверены и подготовлены к машинному обучению.\n",
    "\n",
    "**<a href=\"#learning\">2. Обучение.</a>** Будет обучено несколько видов моделей и измерено качество их предсказаний.\n",
    "\n",
    "**<a href=\"#conclusion\">3. Выводы.</a>** Будут сделаны выводы о возможности и перспективах выявления токсичных текстов.\n",
    "\n",
    "*Примечания:*\n",
    "\n",
    "*1. Подробнее шаги получения моделей отражены в автоматическом оглавлении тетради.*\n",
    "\n",
    "*2. Выполнение тетради может занять **длительное время** (от 10 до 20 мин. в зависимости от производительности компьютера).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-lesson",
   "metadata": {},
   "source": [
    "<a id=\"prepare\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-internship",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-thinking",
   "metadata": {},
   "source": [
    "Подключим все необходимые для дальнейшей работы модули:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "encouraging-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "rnd_state=12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-imperial",
   "metadata": {},
   "source": [
    "### Загрузка и проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-collect",
   "metadata": {},
   "source": [
    "Загрузим данные из файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accepting-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/toxic_comments.csv') # на локальной машине\n",
    "    \n",
    "#data = data.sample(data.shape[0]//30) # для быстрой проверки всей тетради"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-harassment",
   "metadata": {},
   "source": [
    "Проверим структуру и первые несколько записей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cultural-intellectual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-cabinet",
   "metadata": {},
   "source": [
    "Структура и значения соответствуют ожидаемым."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-textbook",
   "metadata": {},
   "source": [
    "Проверим размер загруженного:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "split-reasoning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-roots",
   "metadata": {},
   "source": [
    "Объём данных соответствует задаче машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-humidity",
   "metadata": {},
   "source": [
    "Проверим наличие пропусков в данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "shaped-marsh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-orientation",
   "metadata": {},
   "source": [
    "Пропущенных значений нет:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-sense",
   "metadata": {},
   "source": [
    "Проверим типы значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "later-protocol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     object\n",
       "toxic     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-blogger",
   "metadata": {},
   "source": [
    "Типы столбцов соответствуют хранимой в них информации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-moisture",
   "metadata": {},
   "source": [
    "Проверим дублирование данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blond-departure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum(), data['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-invite",
   "metadata": {},
   "source": [
    "Дублей нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-going",
   "metadata": {},
   "source": [
    "Проверим целевой признак на наличие некорректных значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "anticipated-airplane",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-inspector",
   "metadata": {},
   "source": [
    "Целевой признак принимает значение 0 либо 1. Некорректных значений нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-bhutan",
   "metadata": {},
   "source": [
    "**Итог:** исходные данные загружены, проверены и готовы к использованию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-moses",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-puzzle",
   "metadata": {},
   "source": [
    "Попробуем выяснить язык комментариев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wanted-pound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141442</th>\n",
       "      <td>Nobody needs to explain anything. The 300 albu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19082</th>\n",
       "      <td>\" August 2010 (UTC)\\nI suppose one can assume ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>Russian language==\\n\\nSee Wikipedia:Reference ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51538</th>\n",
       "      <td>Joseph Stalin\\nPlease stop adding unsourced no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92625</th>\n",
       "      <td>\"\\n\\nYou really do need to justify that, BoxOf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94685</th>\n",
       "      <td>(UTC)\\n\\n I recognise what you are saying, but...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79126</th>\n",
       "      <td>That would be fair, provided he advertises it,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94861</th>\n",
       "      <td>, 23 May 2006 (UTC)\\n\\n Those borders are well...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>William Bedell is a good example of the attitu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100817</th>\n",
       "      <td>Sld For Scrap \\n\\nhttp://today.seattletimes.co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "141442  Nobody needs to explain anything. The 300 albu...      0\n",
       "19082   \" August 2010 (UTC)\\nI suppose one can assume ...      0\n",
       "6418    Russian language==\\n\\nSee Wikipedia:Reference ...      0\n",
       "51538   Joseph Stalin\\nPlease stop adding unsourced no...      0\n",
       "92625   \"\\n\\nYou really do need to justify that, BoxOf...      0\n",
       "94685   (UTC)\\n\\n I recognise what you are saying, but...      0\n",
       "79126   That would be fair, provided he advertises it,...      0\n",
       "94861   , 23 May 2006 (UTC)\\n\\n Those borders are well...      0\n",
       "16245   William Bedell is a good example of the attitu...      0\n",
       "100817  Sld For Scrap \\n\\nhttp://today.seattletimes.co...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-ribbon",
   "metadata": {},
   "source": [
    "Случайная выборка говорит о том, что комментарии сделаны на английском языке. Убедимся, что это не случайность и комментариев на русском нет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "supposed-atlas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0016231019420822079, 0.0004010753833716653)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].str.contains(r'[А-Яа-яЁё]').sum() / data.shape[0], \\\n",
    "data['text'].str.contains(r'[А-Яа-яЁё]{2,}\\s+[А-Яа-яЁё]{2,}').sum() / data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-telling",
   "metadata": {},
   "source": [
    "Кириллические символы содержат только 0.16% комментариев, при этом пару русских слов, разделённых пробелом, содержат и того меньше - 0.04% комментариев. Значит, комментарии не русскоязычные, а англоязычные - для лемматизации воспользуемся библиотекой nltk.\n",
    "\n",
    "Лемматизируем комментарии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "appreciated-calendar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/alex/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def lemmatize(text):\n",
    "    try:\n",
    "        return ' '.join([stemmer.stem(w) for w in word_tokenize(\n",
    "            re.sub('[^a-zA-Z]', ' ', text))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "nltk.download('punkt')\n",
    "data['lemm_text'] = data['text'].apply(lambda text: lemmatize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-violence",
   "metadata": {},
   "source": [
    "Проверим, какое число комментариев не удалось лемматизировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aging-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemm_text'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-cholesterol",
   "metadata": {},
   "source": [
    "Посмотрим текст проблеммного комментария:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alternative-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data['lemm_text'].isna().sum() > 0):\n",
    "    excepted_idx = data[data['lemm_text'].isna()].index\n",
    "    excepted_text = data.loc[excepted_idx, 'text'].values[0]\n",
    "    excepted_text[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-kingston",
   "metadata": {},
   "source": [
    "Исправим и лемматизируем проблеммный комментарий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "corresponding-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (data['lemm_text'].isna().sum() > 0):\n",
    "    corrected_text = excepted_text[:excepted_text.index('yyy')]\n",
    "    data.loc[excepted_idx, ['text','lemm_text']] = [corrected_text,\n",
    "        lemmatize(corrected_text)]\n",
    "    data.loc[excepted_idx,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-royalty",
   "metadata": {},
   "source": [
    "**Итог:** все тексты лемматизированы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-bunny",
   "metadata": {},
   "source": [
    "### Деление на выборки для МО"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-logging",
   "metadata": {},
   "source": [
    "Выделим из исходных данных целевые признаки. Перекодируем тексты в векторы, содержащие TF-IDF значения. Разделим данные на обучающую, валидационную и тестовую выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "damaged-white",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "target = data['toxic']\n",
    "#texts  = data['lemm_text'].values.astype('U')\n",
    "texts  = data['lemm_text'].values\n",
    "\n",
    "del data['text']\n",
    "\n",
    "texts_train, texts_x, target_train, target_x = train_test_split(texts, target, \n",
    "    train_size=0.6, random_state=rnd_state)\n",
    "texts_valid, texts_test, target_valid, target_test = train_test_split(texts_x, target_x,\n",
    "    train_size=0.5, random_state=rnd_state)\n",
    "\n",
    "nltk.download('stopwords')\n",
    "#stop_words = set(stopwords.words('russian')) \n",
    "#tf_idf_vectorizer = TfidfVectorizer(stop_words=stop_words) \n",
    "tf_idf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), lowercase=True)#, min_df=0.0001)\n",
    "\n",
    "features_train = tf_idf_vectorizer.fit_transform(texts_train)\n",
    "features_valid = tf_idf_vectorizer.transform(texts_valid)\n",
    "features_test  = tf_idf_vectorizer.transform(texts_test)\n",
    "\n",
    "del texts_x, target_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-alignment",
   "metadata": {},
   "source": [
    "**Итог:** данные для обучения моделей готовы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-algebra",
   "metadata": {},
   "source": [
    "<a id=\"learning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-platinum",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-convertible",
   "metadata": {},
   "source": [
    "Перед обучением моделей выберем метрику для оценки их качества. В качестве основной метрики оценки моделей возьмём F1. Она хорошо отражает баланс между точностью и полнотой. В качестве дополнительной (вспомогательной) метрики возьмём площадь под кривой precision-recall. Она позволит оценить уровень превосходства моделей над моделью, которая делает случайные предсказания (для неё метрика равна 0,5).\n",
    "\n",
    "Обе метрики совсем или мало чувстсвительны к дисбалансу классов, а он в нашем случае имеет место быть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sixth-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10167887648758234"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-arthur",
   "metadata": {},
   "source": [
    "Определим фукцию вычисления метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "southeast-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_n_auc(y_true, y_predicted):\n",
    "    #recall = recall_score(y_true, y_predicted)\n",
    "    f1 = f1_score(y_true, y_predicted)\n",
    "    precisions, recalls, _ = precision_recall_curve(y_true, y_predicted)\n",
    "    pr_auc = auc(recalls, precisions)\n",
    "    #return recall, pr_auc\n",
    "    return f1, pr_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-quality",
   "metadata": {},
   "source": [
    "Обучим модели вида:\n",
    "\n",
    "    - линейная регрессия,\n",
    "    - решающее дерево,\n",
    "    - случайный лес: scikit-learn, LightGBM, CatBoost, XGBoost.\n",
    "    \n",
    "Для моделей каждого вида  создадим по одной подпрограмме. Подпрограммы будут обучать и выбирать модель с лучшими значениями гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "devoted-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_logistic_regression_model(x_train, y_train, x_valid, y_valid):\n",
    "    best_model, best_solver, best_c, best_f1, best_auc = None, 0, 0, 0, 0\n",
    "    #for solver in ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']:\n",
    "    for solver in ['newton-cg']: # сужено для ускорения выполнения тетради\n",
    "        #for c100 in range(40, 101, 5):\n",
    "        for c100 in range(50, 101, 10): # сужено для ускорения выполнения тетради\n",
    "            c = c100 / 100\n",
    "            model = LogisticRegression(random_state=rnd_state, solver=solver,\n",
    "                    class_weight='balanced', max_iter=1000, C=c)\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_valid)\n",
    "            f1, pr_auc = get_f1_n_auc(y_valid, y_pred)\n",
    "            if best_f1 < f1:\n",
    "                best_model, best_solver, best_c, best_f1, best_auc = model, solver, c, f1, pr_auc\n",
    "        print(solver, end=' ')\n",
    "    best_solver = 'solver=\\'{}\\', C={}'.format(best_solver, best_c)\n",
    "    return best_model, best_solver, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-sugar",
   "metadata": {},
   "source": [
    "Создадим функцию обучения моделей решающего дерева с подбором максимальной глубины:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sporting-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_decision_tree_model(x_train, y_train, x_valid, y_valid):\n",
    "    best_model, best_depth, best_f1, best_auc = None, 0, 0, 0\n",
    "    #for depth in range(100, 1001, 100):\n",
    "    for depth in range(1000, 1001, 100): # диапазон сужен для ускорения выполнения тетради\n",
    "        model = DecisionTreeClassifier(random_state=rnd_state, max_depth=depth, \n",
    "            class_weight='balanced')\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_valid)\n",
    "        f1, pr_auc = get_f1_n_auc(y_valid, y_pred)\n",
    "        if best_f1 < f1:\n",
    "            best_model, best_depth, best_f1, best_auc = model, depth, f1, pr_auc\n",
    "        print(depth, end=' ')\n",
    "    best_depth = 'depth=\\'{}\\''.format(depth)\n",
    "    return best_model, best_depth, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-skill",
   "metadata": {},
   "source": [
    "Создадим функцию обучения моделей случайного леса с подбором числа деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "timely-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_random_forest_model(x_train, y_train, x_valid, y_valid):\n",
    "    best_model, best_estimators, best_f1, best_auc = None, 0, 0, 0\n",
    "    #for estimators in range(100,1001,100):\n",
    "    for estimators in range(100,101,100): # сужено для ускорения выполнения тетради\n",
    "        model = RandomForestClassifier(random_state=rnd_state, n_estimators=estimators,\n",
    "            class_weight='balanced')\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_valid)\n",
    "        f1, pr_auc = get_f1_n_auc(y_valid, y_pred)\n",
    "        if best_f1 < f1:\n",
    "            best_model, best_estimators, best_f1, best_auc = model, estimators, f1, pr_auc\n",
    "        print(estimators, end=' ')\n",
    "    best_estimators = 'estimators=\\'{}\\''.format(best_estimators)\n",
    "    return best_model, best_estimators, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-basement",
   "metadata": {},
   "source": [
    "Создадим функцию обучения моделей случайного леса из библиотеки Light GBM с подбором числа деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "golden-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_lightgbm_model(x_train, y_train, x_valid, y_valid):\n",
    "    best_model, best_estimators, best_f1, best_auc = None, 0, 0, 0\n",
    "    #for estimators in range(100,2001,100):\n",
    "    for estimators in range(1075,1076,25): # сужено для ускорения выполнения тетради\n",
    "        model = LGBMClassifier(n_estimators=estimators, random_state=rnd_state,\n",
    "            class_weight='balanced')\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_valid)\n",
    "        f1, pr_auc = get_f1_n_auc(y_valid, y_pred)\n",
    "        if best_f1 < f1:\n",
    "            best_model, best_estimators, best_f1, best_auc = model, estimators, f1, pr_auc\n",
    "        print(estimators, end=' ')\n",
    "    best_estimators = 'estimators=\\'{}\\''.format(best_estimators)\n",
    "    return best_model, best_estimators, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac26e1-eb48-4146-a2ff-cf1345a1e352",
   "metadata": {},
   "source": [
    "Создадим функцию обучения моделей случайного леса из библиотеки CatBoost с подбором числа деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a4a4835-ce5f-4259-b1a8-07cfba2a3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_weight = (target_train == 0).sum() / (target_train == 1).sum()\n",
    "\n",
    "def get_best_catboost_model(x_train, y_train, x_valid, y_valid):\n",
    "    best_model, best_estimators, best_f1, best_auc = None, 0, 0, 0\n",
    "    #for estimators in range(500,2001,250):\n",
    "    for estimators in range(1250,1251,100): # сужено для ускорения выполнения тетради\n",
    "        model = CatBoostClassifier(n_estimators=estimators, random_state=rnd_state,\n",
    "            class_weights=[1,class1_weight], verbose=False)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_valid)\n",
    "        f1, pr_auc = get_f1_n_auc(y_valid, y_pred)\n",
    "        if best_f1 < f1:\n",
    "            best_model, best_estimators, best_f1, best_auc = model, estimators, f1, pr_auc\n",
    "        print(estimators, end=' ')\n",
    "    best_estimators = 'estimators=\\'{}\\''.format(best_estimators)\n",
    "    return best_model, best_estimators, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffdc911-eccc-46e0-943a-b3fcb1bf8544",
   "metadata": {},
   "source": [
    "Создадим функцию обучения моделей случайного леса из библиотеки CatBoost с подбором числа деревьев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c21e0b5-bb2b-4ed4-9413-19a9c49f756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_xgboost_model(x_train, y_train, x_valid, y_valid):\n",
    "    best_model, best_estimators, best_f1, best_auc = None, 0, 0, 0\n",
    "    #for estimators in range(500,2001,250):\n",
    "    for estimators in range(1750,1751,100): # сужено для ускорения выполнения тетради\n",
    "        model = XGBClassifier(n_estimators=estimators, random_state=rnd_state,\n",
    "            scale_pos_weight=class1_weight, verbosity=0, use_label_encoder=False)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_valid)\n",
    "        f1, pr_auc = get_f1_n_auc(y_valid, y_pred)\n",
    "        if best_f1 < f1:\n",
    "            best_model, best_estimators, best_f1, best_auc = model, estimators, f1, pr_auc\n",
    "        print(estimators, end=' ')\n",
    "    best_estimators = 'estimators=\\'{}\\''.format(best_estimators)\n",
    "    return best_model, best_estimators, best_f1, best_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-alert",
   "metadata": {},
   "source": [
    "Создадим отчёт, куда будем записывать результаты обучения моделей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "driving-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame(columns=['model_class', 'model_params', 'f1', 'pr-auc',\n",
    "       'model_object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-monkey",
   "metadata": {},
   "source": [
    "Создадим функцию добавления результатов обучения в отчёт:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hollow-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_add(report, model_name, model_params, recall, pr_auc, model='-'):\n",
    "    uid_columns = report.columns[:2]\n",
    "    report.loc[report.shape[0]] = [model_name, model_params, recall, pr_auc, model]\n",
    "    # Устранение дублей в случае повторного вызова для тех же моделей (при отладке)\n",
    "    report = report[~report.duplicated(keep='last', subset=uid_columns)]\n",
    "    report = report.reset_index(drop=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-prisoner",
   "metadata": {},
   "source": [
    "Обучим модели:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-presence",
   "metadata": {},
   "source": [
    "*Внимание! Чтобы сократить время обучения в подпрограммах искусственно сужены диапазоны перебора значений гиперпараметров. Они сужены к тем значениям, при которых получены наилучшие варианты моделей. В подпрограммы добавлены соответствующие комментарии.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accurate-current",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML begin:\n",
      "\n",
      "Logistic Regression... newton-cg \n",
      "Decision Tree... 1000 \n",
      "Random Forest... 100 \n",
      "LightGBM... 1075 \n",
      "CatBoost... 1250 \n",
      "XGBoost... 1750 \n",
      "ML end.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_class</th>\n",
       "      <th>model_params</th>\n",
       "      <th>f1</th>\n",
       "      <th>pr-auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>solver='newton-cg', C=1.0</td>\n",
       "      <td>0.755760</td>\n",
       "      <td>0.773450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>depth='1000'</td>\n",
       "      <td>0.666572</td>\n",
       "      <td>0.684778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>estimators='100'</td>\n",
       "      <td>0.627764</td>\n",
       "      <td>0.734632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>estimators='1075'</td>\n",
       "      <td>0.778230</td>\n",
       "      <td>0.789110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>estimators='1250'</td>\n",
       "      <td>0.761492</td>\n",
       "      <td>0.775909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>estimators='1750'</td>\n",
       "      <td>0.783931</td>\n",
       "      <td>0.795558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_class               model_params        f1    pr-auc\n",
       "0  Logistic Regression  solver='newton-cg', C=1.0  0.755760  0.773450\n",
       "1        Decision Tree               depth='1000'  0.666572  0.684778\n",
       "2        Random Forest           estimators='100'  0.627764  0.734632\n",
       "3             LightGBM          estimators='1075'  0.778230  0.789110\n",
       "4             CatBoost          estimators='1250'  0.761492  0.775909\n",
       "5              XGBoost          estimators='1750'  0.783931  0.795558"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('ML begin:')\n",
    "\n",
    "trainer_names = ['Logistic Regression', 'Decision Tree', 'Random Forest', \n",
    "                 'LightGBM', 'CatBoost', 'XGBoost']\n",
    "trainers = [get_best_logistic_regression_model, get_best_decision_tree_model,\n",
    "            get_best_random_forest_model, get_best_lightgbm_model,\n",
    "            get_best_catboost_model, get_best_xgboost_model]\n",
    "\n",
    "#trainer_names = ['XGBoost']\n",
    "#trainers = [get_best_xgboost_model]\n",
    "\n",
    "for trainer_name, trainer in zip(trainer_names, trainers):\n",
    "    print('\\n' + trainer_name + '...', end=' ')\n",
    "    model, model_params, recall, pr_auc = trainer(features_train, target_train, \n",
    "        features_valid, target_valid)\n",
    "    report = report_add(report, trainer_name, model_params, recall, pr_auc, model) \n",
    "\n",
    "print('\\nML end.')\n",
    "report[report.columns[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-berlin",
   "metadata": {},
   "source": [
    "На валидационной выборке все модели проходят тест на адекватность. Их precision-recall AUC заметно больше 0.5 (значения модели, делающей случайные предсказания). Лучшее качество у моделей ... , худшее у Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-double",
   "metadata": {},
   "source": [
    "Выполним итоговую проверку моделей на тестовой выборке и дополнительно выведем метрику recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "optional-brush",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_class</th>\n",
       "      <th>model_params</th>\n",
       "      <th>f1</th>\n",
       "      <th>pr-auc</th>\n",
       "      <th>f1-test</th>\n",
       "      <th>pr-auc-test</th>\n",
       "      <th>recall-test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>solver='newton-cg', C=1.0</td>\n",
       "      <td>0.755760</td>\n",
       "      <td>0.773450</td>\n",
       "      <td>0.752397</td>\n",
       "      <td>0.770790</td>\n",
       "      <td>0.855763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>depth='1000'</td>\n",
       "      <td>0.666572</td>\n",
       "      <td>0.684778</td>\n",
       "      <td>0.655963</td>\n",
       "      <td>0.674601</td>\n",
       "      <td>0.712773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>estimators='100'</td>\n",
       "      <td>0.627764</td>\n",
       "      <td>0.734632</td>\n",
       "      <td>0.618402</td>\n",
       "      <td>0.726012</td>\n",
       "      <td>0.461682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>estimators='1075'</td>\n",
       "      <td>0.778230</td>\n",
       "      <td>0.789110</td>\n",
       "      <td>0.771180</td>\n",
       "      <td>0.782204</td>\n",
       "      <td>0.786916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>estimators='1250'</td>\n",
       "      <td>0.761492</td>\n",
       "      <td>0.775909</td>\n",
       "      <td>0.759626</td>\n",
       "      <td>0.774249</td>\n",
       "      <td>0.835826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>estimators='1750'</td>\n",
       "      <td>0.783931</td>\n",
       "      <td>0.795558</td>\n",
       "      <td>0.782841</td>\n",
       "      <td>0.794166</td>\n",
       "      <td>0.776012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_class               model_params        f1    pr-auc  \\\n",
       "0  Logistic Regression  solver='newton-cg', C=1.0  0.755760  0.773450   \n",
       "1        Decision Tree               depth='1000'  0.666572  0.684778   \n",
       "2        Random Forest           estimators='100'  0.627764  0.734632   \n",
       "3             LightGBM          estimators='1075'  0.778230  0.789110   \n",
       "4             CatBoost          estimators='1250'  0.761492  0.775909   \n",
       "5              XGBoost          estimators='1750'  0.783931  0.795558   \n",
       "\n",
       "    f1-test  pr-auc-test  recall-test  \n",
       "0  0.752397     0.770790     0.855763  \n",
       "1  0.655963     0.674601     0.712773  \n",
       "2  0.618402     0.726012     0.461682  \n",
       "3  0.771180     0.782204     0.786916  \n",
       "4  0.759626     0.774249     0.835826  \n",
       "5  0.782841     0.794166     0.776012  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics = report.apply(axis=1, func=lambda row: \n",
    "    get_f1_n_auc(target_test, row['model_object'].predict(features_test)))\n",
    "test_data = pd.DataFrame(zip(*test_metrics)).T\n",
    "test_data.columns = ['f1-test', 'pr-auc-test']\n",
    "report = report.join(test_data)\n",
    "report['recall-test'] = report.apply(axis=1, func=lambda row: \n",
    "    recall_score(target_test, row['model_object'].predict(features_test)))\n",
    "columns_to_show = report.columns.to_list()\n",
    "columns_to_show.remove('model_object')\n",
    "report[columns_to_show]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-spanking",
   "metadata": {},
   "source": [
    "На тестовой выборке все модели показали тот же уровень качества и адекватности, что и на валидационной выборке (значения метрик практически не изменились)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-kuwait",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-christopher",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-prevention",
   "metadata": {},
   "source": [
    "Обучение разных видов моделей показало, что автоматическое выявление токсичных текстов в описаниях продуктов и комментариях к ним возможно. Лучшие **модели машинного обучения позволяют выявить примерно 80%-86% токсичных текстов** (метрика recall).\n",
    "\n",
    "Повысить уровень выявления токсичных текстов можно как путём использования более совершенных моделей (например, модели **BERT**, способной учитывать контекст), так и путём использования **ручной обработки**. В последнем случае модель будет выдавать вероятность того, что текст токсичен, в диапазоне от 0 до 100%. Тексты, для которых вероятность выше заданного верхнего порога, будут автоматически относится к токсичными. Тексты, для которых вероятность окажется ниже заданного нижнего порога, будут автоматически относится к нетоксичным. Остальные комментарии будут проверяться операторами вручную. (Сейчас модели автоматически относят комментарий к токсичным, если вероятность больше 0,5, и к нетоксичным в противном случае.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6595d2f-bcf1-4bd3-903b-d25d681b73ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
